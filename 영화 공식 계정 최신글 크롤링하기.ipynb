{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인스타그램 계정별로 크롤링하기\n",
    "\n",
    "* 전달받은 데이터셋 : 영화홍보 or 영화 제작사 등 특정 영화의 공식 인스타그램 계정 아이디가 있는 데이터\n",
    "* 작업 목적 : 당사의 어플('마이무비')에서 해당 영화의 인스타그램 피드 정보를 추가적으로 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pyquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# 계정 아이디 주소가 들어있는 파일 \n",
    "df = pd.read_excel(\"crawl_list_add_title.xlsx\")\n",
    "\n",
    "def get_web_html(url):\n",
    "\n",
    "    global rest\n",
    "    rest = random.randint(10,12)\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        time.sleep(rest)\n",
    "        # http 응답 상태 코드로 확인\n",
    "        if response.status_code == 200: # 서버에 요청한 페이지가 있을 때\n",
    "            return response.text\n",
    "        else:\n",
    "            print('Wrong：', response.status_code)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    \n",
    "data_list = []\n",
    "error_list = []\n",
    "ommision_list = []\n",
    "today = datetime.today().strftime(\"%m%d\")\n",
    "\n",
    "\n",
    "for idx,movie_list in tqdm(df[0:len(df)].iterrows(), desc=\"돌리는중\"):\n",
    "    \n",
    "    cnt = 0\n",
    "    mei_pk = movie_list['mei_pk']\n",
    "    instagram_id = movie_list['instagram_id']\n",
    "    title = movie_list['title']\n",
    "\n",
    "    # imdb_id = movie_list['imdb_id']\n",
    "    print(instagram_id) \n",
    "    url = 'https://www.instagram.com/' + str(movie_list['instagram_id'])\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'\n",
    "    }\n",
    "    html = get_web_html(url)\n",
    "    \n",
    "    \n",
    "    try : \n",
    "        user_id = re.findall('profilePage_([0-9]+)', html, re.S)[0]\n",
    "        doc = pyquery.PyQuery(html)\n",
    "        items = doc('script[type=\"text/javascript\"]').items()\n",
    "    \n",
    "        for item in items:\n",
    "            if item.text().strip().startswith('window._sharedData'):\n",
    "                js_data = json.loads(item.text()[21:-1], encoding='utf-8')\n",
    "                edges = js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['edges']\n",
    "                cursor = \\\n",
    "                js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['page_info'][\n",
    "                    'end_cursor']\n",
    "                flag = js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['page_info']['has_next_page']\n",
    "                \n",
    "                \n",
    "                \n",
    "                for edge in edges:\n",
    "                    shortcode = edge['node']['shortcode']\n",
    "                    peed_url = 'https://www.instagram.com/p/' + shortcode\n",
    "                    img_url = peed_url + '/media/?size=l'\n",
    "                    cnt = cnt + 1\n",
    "                    #print(cnt)\n",
    "                    \n",
    "                    if cnt == 1 :\n",
    "                        peed_post = 'most recent post of '+ str(title) +'\\'s official instagram page'\n",
    "                    if cnt == 2 :\n",
    "                        peed_post = '2nd recent post of '+ str(title)  +'\\'s official instagram page'\n",
    "                    if cnt == 3 :\n",
    "                        peed_post = '3rd recent post of '+ str(title)  +'\\'s official instagram page'\n",
    "                        \n",
    "                    elif  3 < cnt < 11 :\n",
    "                        peed_post = str(cnt) +'th recent post of ' + str(title) +'\\'s offical instagram page'\n",
    "                    \n",
    "                    else : \n",
    "                        pass\n",
    "                    \n",
    "                    data = {\n",
    "                            \"mei_pk\" :mei_pk,\n",
    "                            \"series_id\":series_id,\n",
    "                            \"imdb_id\":imdb_id,\n",
    "                            \"instagram_id\": instagram_id,\n",
    "                            \"img_url\" : img_url, \n",
    "                            \"peed_url\" : peed_url,\n",
    "                            \"peed_post\" : peed_post,\n",
    "                            \"tmdb_id\" : tmdb_id\n",
    "                           }\n",
    "                    \n",
    "                    if cnt < 11 :\n",
    "                        data_list.append(data)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # get_twelve_post(edges)\n",
    "                # 계정은 있으나 비공개 계정이거나 게시글이 아예 없을 때\n",
    "                if (flag == False) & (len(edges) == 0):\n",
    "                    ommision = {\"instagram_id\":instagram_id}\n",
    "                    ommision_list.append(ommision)\n",
    "                else : \n",
    "                    pass\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    except :\n",
    "        # url 정보를 가져올 수 없을 때 (계정이 없는 경우임. 페이지 없음)---> 예외처리\n",
    "        error = {\"instagram_id\":instagram_id}\n",
    "        error_list.append(error)\n",
    "        print('error page - !')\n",
    "\n",
    "    if (idx+1) % 50 == 0 :\n",
    "        time.sleep(50)\n",
    "    else :\n",
    "        pass  \n",
    "\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(data_list,\n",
    "                         columns=[\"instagram_id\", \"img_url\",  \"peed_post\", \"peed_url\"])\n",
    "error_df = pd.DataFrame(error_list,\n",
    "                         columns=[\"instagram_id\"])\n",
    "ommision_df = pd.DataFrame(ommision_list,\n",
    "                         columns=[\"instagram_id\"])\n",
    "\n",
    "# 정상 크롤링 데이터\n",
    "# url 오류로 엑셀 변환시 데이터삽입안되서 다음과 같은 옵션 추가해야함\n",
    "url_preserve = pd.ExcelWriter(f'/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_result_{today}_3.xlsx', options={'strings_to_urls': False})\n",
    "result_df.to_excel(url_preserve)\n",
    "url_preserve.save()\n",
    "\n",
    "# 계정 존재하지 않는 에러 데이터 \n",
    "error_df.to_excel(f\"/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_error_{today}_3.xlsx\")\n",
    "\n",
    "# 비공개 계정 or 게시글 없는 계정 데이터\n",
    "ommision_df.to_excel(f\"/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_none_{today}_3.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
