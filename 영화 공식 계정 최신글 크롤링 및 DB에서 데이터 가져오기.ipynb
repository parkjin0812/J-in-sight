{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인스타그램 계정별로 크롤링하기\n",
    "\n",
    "* 전달받은 데이터셋 : 영화홍보 or 영화 제작사 등 특정 영화의 공식 인스타그램 계정 아이디가 있는 데이터\n",
    "* 작업 목적 : 당사의 어플('마이무비')에서 해당 영화의 인스타그램 피드 정보를 추가적으로 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pyquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "today = datetime.today().strftime(\"%m%d\")\n",
    "\n",
    "\n",
    "def db_connection(host_name='ds'): \n",
    "    \n",
    "    host_url = \"\"\n",
    "    user_nm = \"\"\n",
    "    passwd = \"\"\n",
    "    port_num = \n",
    "    db_name = \"\"\n",
    "    \n",
    "    conn = pymysql.connect(host=host_url, user=user_nm, passwd=passwd, port = port_num, charset='utf8', db = db_name,cursorclass=pymysql.cursors.DictCursor) # cursorclass=pymysql.cursors.DictCursor 추가     # db=db,\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def at(x):\n",
    "    x = str(x)\n",
    "    x = x.replace(\"@\",\"\")\n",
    "    x = x.replace(\"=\",\"\")\n",
    "    return x\n",
    "\n",
    "def get_web_html(url):\n",
    "\n",
    "    global rest\n",
    "    rest = random.randint(10,12)\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        time.sleep(rest)\n",
    "        # http 응답 상태 코드로 확인\n",
    "        if response.status_code == 200: # 서버에 요청한 페이지가 있을 때\n",
    "            return response.text\n",
    "        else:\n",
    "            print('Wrong：', response.status_code)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def blank(x):\n",
    "    x = x.strip()\n",
    "    x = x.replace('\\r','')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def strange_r(x):\n",
    "    \n",
    "    x = x.replace('\\r','')\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "title_sql = '''\n",
    "select 칼럼명 from movie_data;\n",
    "'''\n",
    "\n",
    "instagram_sql = '''\n",
    "select 칼럼명\n",
    "where instagram_id is not null;\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "cursor = db_connection().cursor()\n",
    "cursor.execute(title_sql)\n",
    "title_list = pd.DataFrame(cursor.fetchall())\n",
    "time.sleep(1)\n",
    "\n",
    "cursor.execute(instagram_sql)\n",
    "insta_list = pd.DataFrame(cursor.fetchall())\n",
    "\n",
    "\n",
    "\n",
    "insta_list['instagram_id'] = insta_list['instagram_id'].apply(at)\n",
    "\n",
    "crawl_list = insta_list.merge(title_list, on=['기준칼럼들'], how='left')\n",
    "\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'www.instagram.com']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'instagram.com']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'explore']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'p']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'www.instagram']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'Instagram']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'Instagram.com']\n",
    "crawl_list = crawl_list[crawl_list['instagram_id'] != 'instagram']\n",
    "\n",
    "\n",
    "error_list = []\n",
    "data_list = []\n",
    "ommision_list = []\n",
    "\n",
    "\n",
    "# 계정 아이디가 들어있는 데이터 프레임을 한 줄씩 보냄\n",
    "for idx,movie_list in tqdm(crawl_list[2500:-1].iterrows(), desc=\"돌리는중\"):\n",
    "    cnt = 0\n",
    "    기준칼럼1 = movie_list['']\n",
    "    기준칼럼2 = movie_list['']\n",
    "    instagram_id = movie_list['instagram_id']\n",
    "    title = movie_list['title']\n",
    "    기준칼럼3 = movie_list['']\n",
    "    기준칼럼4 = movie_list['']\n",
    "\n",
    "\n",
    "    print(instagram_id) \n",
    "    url = 'https://www.instagram.com/' + str(movie_list['instagram_id'])\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'\n",
    "    }\n",
    "    html = get_web_html(url)\n",
    "\n",
    "    try : \n",
    "        user_id = re.findall('profilePage_([0-9]+)', html, re.S)[0]\n",
    "        doc = pyquery.PyQuery(html)\n",
    "        items = doc('script[type=\"text/javascript\"]').items()\n",
    "        # query latest 12 post\n",
    "        for item in items:\n",
    "            if item.text().strip().startswith('window._sharedData'):\n",
    "                js_data = json.loads(item.text()[21:-1], encoding='utf-8')\n",
    "                edges = js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['edges']\n",
    "                cursor = \\\n",
    "                js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['page_info'][\n",
    "                    'end_cursor']\n",
    "                flag = js_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media']['page_info']['has_next_page']\n",
    "                \n",
    "                \n",
    "                \n",
    "                for edge in edges:\n",
    "                    shortcode = edge['node']['shortcode']\n",
    "                    peed_url = 'https://www.instagram.com/p/' + shortcode\n",
    "                    img_url = peed_url + '/media/?size=l'\n",
    "                    cnt = cnt + 1\n",
    "                    #print(cnt)\n",
    "                    \n",
    "                    if cnt == 1 :\n",
    "                        peed_post = 'most recent post of '+ str(title) +'\\'s official instagram page'\n",
    "                    if cnt == 2 :\n",
    "                        peed_post = '2nd recent post of '+ str(title)  +'\\'s official instagram page'\n",
    "                    if cnt == 3 :\n",
    "                        peed_post = '3rd recent post of '+ str(title)  +'\\'s official instagram page'\n",
    "                        \n",
    "                    elif  3 < cnt < 11 :\n",
    "                        peed_post = str(cnt) +'th recent post of ' + str(title) +'\\'s offical instagram page'\n",
    "                    \n",
    "                    else : \n",
    "                        pass\n",
    "                    \n",
    "                    data = {\n",
    "                            \"기준칼럼1\" :기준칼럼1,\n",
    "                            \"기준칼럼2\":기준칼럼2,\n",
    "                            \"기준칼럼3\":기준칼럼3,\n",
    "                            \"기준칼럼4\" : 기준칼럼4,\n",
    "                            \"instagram_id\": instagram_id,\n",
    "                            \"img_url\" : img_url, \n",
    "                            \"peed_post\" : peed_post,\n",
    "                            \"peed_url\" : peed_url\n",
    "                           }\n",
    "                    \n",
    "                    if cnt < 11 :\n",
    "                        data_list.append(data)   \n",
    "                \n",
    "                # get_twelve_post(edges)\n",
    "                # 계정은 있으나 비공개 계정이거나 게시글이 아예 없을 때\n",
    "                if (flag == False) & (len(edges) == 0):\n",
    "                    ommision = {\"instagram_id\":instagram_id}\n",
    "                    ommision_list.append(ommision)\n",
    "                else : \n",
    "                    pass\n",
    "\n",
    "    except :\n",
    "        # url 정보를 가져올 수 없을 때 (계정이 없는 경우임. 페이지 없음)---> 예외처리\n",
    "        error = {\"instagram_id\":instagram_id}\n",
    "        error_list.append(error)\n",
    "        print('error page - !')\n",
    "\n",
    "    if (idx+1) % 50 == 0 :\n",
    "        time.sleep(50)\n",
    "    else :\n",
    "        pass  \n",
    "\n",
    "result_df = pd.DataFrame(data_list)\n",
    "error_df = pd.DataFrame(error_list)\n",
    "ommision_df = pd.DataFrame(ommision_list)\n",
    "\n",
    "\n",
    "result_df['peed_url'] = result_df['peed_url'].apply(blank)\n",
    "result_df['img_url'] = result_df['img_url'].apply(blank)\n",
    "result_df['peed_post'] = result_df['peed_post'].apply(strange_r)\n",
    "\n",
    "# 정상 크롤링 데이터\n",
    "# url 오류로 엑셀 변환시 데이터삽입안되서 다음과 같은 옵션 추가해야함\n",
    "url_preserve = pd.ExcelWriter(f'/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_result_{today}.xlsx', options={'strings_to_urls': False})\n",
    "result_df.to_excel(url_preserve)\n",
    "url_preserve.save()\n",
    "# 계정 존재하지 않는 에러 데이터 \n",
    "error_df.to_excel(f\"/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_error_{today}.xlsx\")\n",
    "# 비공개 계정 or 게시글 없는 계정 데이터\n",
    "ommision_df.to_excel(f\"/Users/myhellebs/Desktop/maimovie_instagram/maimovie_insta_crawling_none_{today}.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
